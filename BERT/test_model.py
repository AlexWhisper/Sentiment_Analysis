import os
# è®¾ç½®Hugging Faceé•œåƒç«™ï¼Œå¿…é¡»åœ¨å¯¼å…¥transformersä¹‹å‰è®¾ç½®

import torch
import numpy as np
import sys
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model import BERTSentimentAnalyzer, binary_accuracy
from data_loader import prepare_data, analyze_text_lengths
from inference import BERTInference
def test_model_creation():
    """
    æµ‹è¯•æ¨¡å‹åˆ›å»º
    """
    print("\n=== æµ‹è¯•æ¨¡å‹åˆ›å»º ===")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = BERTSentimentAnalyzer(model_name='bert-base-uncased', num_classes=2)
        print("âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        info = model.get_model_info()
        print(f"âœ“ æ¨¡å‹å‚æ•°æ€»æ•°: {info['total_parameters']:,}")
        print(f"âœ“ å¯è®­ç»ƒå‚æ•°: {info['trainable_parameters']:,}")
        print(f"âœ“ æ¨¡å‹å¤§å°: {info['model_size_mb']:.1f} MB")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_data_loading():
    """
    æµ‹è¯•æ•°æ®åŠ è½½
    """
    print("\n=== æµ‹è¯•æ•°æ®åŠ è½½ ===")
    
    try:
        # å‡†å¤‡å°æ‰¹é‡æ•°æ®è¿›è¡Œæµ‹è¯•
        print("æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®...")
        train_loader, val_loader, test_loader, tokenizer = prepare_data(
            batch_size=4,  # å°æ‰¹é‡æµ‹è¯•
            max_length=128  # è¾ƒçŸ­åºåˆ—æµ‹è¯•
        )
        
        print("âœ“ æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"âœ“ è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"âœ“ éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        print(f"âœ“ æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch in train_loader:
            print(f"âœ“ æ‰¹æ¬¡å½¢çŠ¶æ£€æŸ¥:")
            print(f"  input_ids: {batch['input_ids'].shape}")
            print(f"  attention_mask: {batch['attention_mask'].shape}")
            print(f"  labels: {batch['labels'].shape}")
            
            # æ£€æŸ¥æ•°æ®ç±»å‹
            assert batch['input_ids'].dtype == torch.long
            assert batch['attention_mask'].dtype == torch.long
            assert batch['labels'].dtype == torch.long
            print("âœ“ æ•°æ®ç±»å‹æ£€æŸ¥é€šè¿‡")
            
            break
        
        return train_loader, val_loader, test_loader, tokenizer
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None, None, None

def test_model_forward():
    """
    æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
    """
    print("\n=== æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­ ===")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = BERTSentimentAnalyzer(model_name='bert-base-uncased', num_classes=2)
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        seq_length = 64
        
        input_ids = torch.randint(0, 1000, (batch_size, seq_length))
        attention_mask = torch.ones(batch_size, seq_length)
        labels = torch.randint(0, 2, (batch_size,))
        
        print(f"âœ“ æµ‹è¯•æ•°æ®åˆ›å»º: batch_size={batch_size}, seq_length={seq_length}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
        
        print(f"âœ“ å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"âœ“ è¾“å‡ºlogitså½¢çŠ¶: {outputs.logits.shape}")
        print(f"âœ“ æŸå¤±å€¼: {outputs.loss.item():.4f}")
        
        # æµ‹è¯•å‡†ç¡®ç‡è®¡ç®—
        accuracy = binary_accuracy(outputs.logits, labels)
        print(f"âœ“ å‡†ç¡®ç‡è®¡ç®—: {accuracy:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_prediction():
    """
    æµ‹è¯•æ¨¡å‹é¢„æµ‹åŠŸèƒ½
    """
    print("\n=== æµ‹è¯•æ¨¡å‹é¢„æµ‹åŠŸèƒ½ ===")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = BERTSentimentAnalyzer(model_name='bert-base-uncased', num_classes=2)
        model.eval()
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "This movie is absolutely fantastic!",
            "I hate this boring film.",
            "The movie is okay, not bad.",
            "Amazing acting and great story!",
            "Terrible plot and bad acting."
        ]
        
        print("æ­£åœ¨æµ‹è¯•é¢„æµ‹åŠŸèƒ½...")
        
        for i, text in enumerate(test_texts):
            try:
                prediction, probability = model.predict(text, max_length=128)
                sentiment = "æ­£é¢" if prediction == 1 else "è´Ÿé¢"
                print(f"âœ“ æ–‡æœ¬{i+1}: {sentiment} (æ¦‚ç‡: {probability:.4f})")
                print(f"  åŸæ–‡: {text[:50]}{'...' if len(text) > 50 else ''}")
            except Exception as e:
                print(f"âœ— æ–‡æœ¬{i+1}é¢„æµ‹å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        print(f"âœ— é¢„æµ‹åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_inference_class():
    """
    æµ‹è¯•æ¨ç†ç±»
    """
    print("\n=== æµ‹è¯•æ¨ç†ç±» ===")
    
    try:
        # åˆ›å»ºæ¨ç†å™¨ï¼ˆä¸åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰
        inferencer = BERTInference(model_name='bert-base-uncased')
        inferencer._load_pretrained_model()  # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        
        print("âœ“ æ¨ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å•æ–‡æœ¬é¢„æµ‹
        test_text = "This is a great movie with excellent acting!"
        result = inferencer.predict_single(test_text, return_details=True)
        
        if 'error' not in result:
            print("âœ“ å•æ–‡æœ¬é¢„æµ‹æˆåŠŸ")
            print(f"  æƒ…æ„Ÿ: {result['sentiment']}")
            print(f"  æ¦‚ç‡: {result['probability']:.4f}")
            print(f"  ç½®ä¿¡åº¦: {result['confidence']}")
        else:
            print(f"âœ— å•æ–‡æœ¬é¢„æµ‹å¤±è´¥: {result['error']}")
            return False
        
        # æµ‹è¯•æ‰¹é‡é¢„æµ‹
        test_texts = [
            "I love this movie!",
            "This film is terrible.",
            "Not bad, could be better."
        ]
        
        results = inferencer.predict_batch(test_texts, batch_size=2)
        
        if len(results) == len(test_texts):
            print("âœ“ æ‰¹é‡é¢„æµ‹æˆåŠŸ")
            for i, result in enumerate(results):
                if 'error' not in result:
                    print(f"  æ–‡æœ¬{i+1}: {result['sentiment']} ({result['probability']:.4f})")
                else:
                    print(f"  æ–‡æœ¬{i+1}: é¢„æµ‹å¤±è´¥")
        else:
            print("âœ— æ‰¹é‡é¢„æµ‹å¤±è´¥")
            return False
        
        return True
        
    except Exception as e:
        print(f"âœ— æ¨ç†ç±»æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_optimizer_setup():
    """
    æµ‹è¯•ä¼˜åŒ–å™¨è®¾ç½®
    """
    print("\n=== æµ‹è¯•ä¼˜åŒ–å™¨è®¾ç½® ===")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        model = BERTSentimentAnalyzer(model_name='bert-base-uncased', num_classes=2)
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        num_training_steps = 1000
        num_warmup_steps = 100
        
        model.setup_optimizer(
            learning_rate=2e-5,
            weight_decay=0.01,
            num_training_steps=num_training_steps,
            num_warmup_steps=num_warmup_steps
        )
        
        print("âœ“ ä¼˜åŒ–å™¨è®¾ç½®æˆåŠŸ")
        print(f"âœ“ ä¼˜åŒ–å™¨ç±»å‹: {type(model.optimizer).__name__}")
        print(f"âœ“ è°ƒåº¦å™¨ç±»å‹: {type(model.scheduler).__name__}")
        print(f"âœ“ å‚æ•°ç»„æ•°é‡: {len(model.optimizer.param_groups)}")
        
        # æ£€æŸ¥å‚æ•°ç»„
        for i, group in enumerate(model.optimizer.param_groups):
            print(f"  ç»„{i+1}: {len(group['params'])}ä¸ªå‚æ•°, æƒé‡è¡°å‡={group['weight_decay']}")
        
        return True
        
    except Exception as e:
        print(f"âœ— ä¼˜åŒ–å™¨è®¾ç½®å¤±è´¥: {e}")
        return False

def test_device_compatibility():
    """
    æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§
    """
    print("\n=== æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§ ===")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    cuda_available = torch.cuda.is_available()
    print(f"CUDAå¯ç”¨: {cuda_available}")
    
    if cuda_available:
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # æµ‹è¯•CPUè®¾å¤‡
    try:
        device = torch.device('cpu')
        model = BERTSentimentAnalyzer(model_name='bert-base-uncased', num_classes=2)
        model.to(device)
        print("âœ“ CPUè®¾å¤‡å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        
        # å¦‚æœæœ‰CUDAï¼Œæµ‹è¯•GPUè®¾å¤‡
        if cuda_available:
            device = torch.device('cuda')
            model.to(device)
            print("âœ“ GPUè®¾å¤‡å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âœ— è®¾å¤‡å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_all_tests():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    """
    print("å¼€å§‹BERTæ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    print("=" * 60)
    
    tests = [
        ("è®¾å¤‡å…¼å®¹æ€§", test_device_compatibility),
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("ä¼˜åŒ–å™¨è®¾ç½®", test_optimizer_setup),
        ("æ¨¡å‹å‰å‘ä¼ æ’­", test_model_forward),
        ("æ¨¡å‹é¢„æµ‹åŠŸèƒ½", test_model_prediction),
        ("æ¨ç†ç±»", test_inference_class),
        # ("æ•°æ®åŠ è½½", test_data_loading),  # å¯èƒ½éœ€è¦ç½‘ç»œä¸‹è½½ï¼Œæ”¾åœ¨æœ€å
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
                print(f"âœ“ {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âœ— {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âœ— {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    # å¯é€‰çš„æ•°æ®åŠ è½½æµ‹è¯•
    print(f"\n{'='*20} æ•°æ®åŠ è½½ï¼ˆå¯é€‰ï¼‰ {'='*20}")
    print("æ³¨æ„: æ­¤æµ‹è¯•éœ€è¦ç½‘ç»œè¿æ¥ä¸‹è½½æ•°æ®é›†")
    try:
        user_input = input("æ˜¯å¦è¿è¡Œæ•°æ®åŠ è½½æµ‹è¯•ï¼Ÿ(y/N): ").strip().lower()
        if user_input in ['y', 'yes']:
            if test_data_loading()[0] is not None:
                passed += 1
                total += 1
                print("âœ“ æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡")
            else:
                total += 1
                print("âœ— æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥")
        else:
            print("è·³è¿‡æ•°æ®åŠ è½½æµ‹è¯•")
    except KeyboardInterrupt:
        print("\nè·³è¿‡æ•°æ®åŠ è½½æµ‹è¯•")
    
    # æµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    print(f"é€šè¿‡: {passed}/{total}")
    print(f"æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼BERTæ¨¡å‹åŠŸèƒ½æ­£å¸¸")
    else:
        print(f"âš ï¸  æœ‰ {total-passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    print("\næµ‹è¯•å®Œæˆ")
    return passed == total

if __name__ == "__main__":
    run_all_tests()